{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Architecture Documentation Demo Table of Contents Instructions Solution Architecture Enterprise Architecture and Innovation Technical Architecture Overview Purpose This site is an integration test to determine the feasibility of treating architecture documentation as code, leveraging Markdown, Git, and GitBook. This test uses GitHub, but could just as easily use GitLab. The publishing flow works like this. To view the test file, demonstrating the syntax of Markdown, click here","title":"Architecture Documentation Demo"},{"location":"#architecture-documentation-demo","text":"","title":"Architecture Documentation Demo"},{"location":"#table-of-contents","text":"Instructions Solution Architecture Enterprise Architecture and Innovation Technical Architecture Overview","title":"Table of Contents"},{"location":"#purpose","text":"This site is an integration test to determine the feasibility of treating architecture documentation as code, leveraging Markdown, Git, and GitBook. This test uses GitHub, but could just as easily use GitLab. The publishing flow works like this. To view the test file, demonstrating the syntax of Markdown, click here","title":"Purpose"},{"location":"ArchitectureDocsOverview/","text":"Architecture Docs Overview Table of Contents Overview Philosophy Inline HTML Automatic Escaping for Special Characters Block Elements Paragraphs and Line Breaks Headers Blockquotes Lists Code Blocks Horizontal Rules Span Elements Links Emphasis Code Images Miscellaneous Backslash Escapes Automatic Links","title":"Architecture Docs Overview"},{"location":"ArchitectureDocsOverview/#architecture-docs-overview","text":"","title":"Architecture Docs Overview"},{"location":"ArchitectureDocsOverview/#table-of-contents","text":"Overview Philosophy Inline HTML Automatic Escaping for Special Characters Block Elements Paragraphs and Line Breaks Headers Blockquotes Lists Code Blocks Horizontal Rules Span Elements Links Emphasis Code Images Miscellaneous Backslash Escapes Automatic Links","title":"Table of Contents"},{"location":"Enterprise_Architecture/","text":"3. Enterprise Architecture Table of Contents Overview Philosophy Inline HTML Automatic Escaping for Special Characters Block Elements Paragraphs and Line Breaks Headers Blockquotes Lists Code Blocks Horizontal Rules Span Elements Links Emphasis Code Images Miscellaneous Backslash Escapes Automatic Links","title":"3. Enterprise Architecture"},{"location":"Enterprise_Architecture/#3-enterprise-architecture","text":"","title":"3. Enterprise Architecture"},{"location":"Enterprise_Architecture/#table-of-contents","text":"Overview Philosophy Inline HTML Automatic Escaping for Special Characters Block Elements Paragraphs and Line Breaks Headers Blockquotes Lists Code Blocks Horizontal Rules Span Elements Links Emphasis Code Images Miscellaneous Backslash Escapes Automatic Links","title":"Table of Contents"},{"location":"Instructions/MarkdownSyntax/","text":"================ Main Basics Syntax License Dingus Overview Philosophy Inline HTML Automatic Escaping for Special Characters Block Elements Paragraphs and Line Breaks Headers Blockquotes Lists Code Blocks Horizontal Rules Span Elements Links Emphasis Code Images Miscellaneous Backslash Escapes Automatic Links Note: This document is itself written using Markdown; you can see the source for it by adding '.text' to the URL . Overview Philosophy Markdown is intended to be as easy-to-read and easy-to-write as is feasible. Readability, however, is emphasized above all else. A Markdown-formatted document should be publishable as-is, as plain text, without looking like it's been marked up with tags or formatting instructions. While Markdown's syntax has been influenced by several existing text-to-HTML filters -- including Setext , atx , Textile , reStructuredText , Grutatext , and EtText -- the single biggest source of inspiration for Markdown's syntax is the format of plain text email. To this end, Markdown's syntax is comprised entirely of punctuation characters, which punctuation characters have been carefully chosen so as to look like what they mean. E.g., asterisks around a word actually look like *emphasis*. Markdown lists look like, well, lists. Even blockquotes look like quoted passages of text, assuming you've ever used email. Inline HTML Markdown's syntax is intended for one purpose: to be used as a format for writing for the web. Markdown is not a replacement for HTML, or even close to it. Its syntax is very small, corresponding only to a very small subset of HTML tags. The idea is not to create a syntax that makes it easier to insert HTML tags. In my opinion, HTML tags are already easy to insert. The idea for Markdown is to make it easy to read, write, and edit prose. HTML is a publishing format; Markdown is a writing format. Thus, Markdown's formatting syntax only addresses issues that can be conveyed in plain text. For any markup that is not covered by Markdown's syntax, you simply use HTML itself. There's no need to preface it or delimit it to indicate that you're switching from Markdown to HTML; you just use the tags. The only restrictions are that block-level HTML elements -- e.g. <div> , <table> , <pre> , <p> , etc. -- must be separated from surrounding content by blank lines, and the start and end tags of the block should not be indented with tabs or spaces. Markdown is smart enough not to add extra (unwanted) <p> tags around HTML block-level tags. For example, to add an HTML table to a Markdown article: This is a regular paragraph. <table> <tr> <td>Foo</td> </tr> </table> This is another regular paragraph. Note that Markdown formatting syntax is not processed within block-level HTML tags. E.g., you can't use Markdown-style *emphasis* inside an HTML block. Span-level HTML tags -- e.g. <span> , <cite> , or <del> -- can be used anywhere in a Markdown paragraph, list item, or header. If you want, you can even use HTML tags instead of Markdown formatting; e.g. if you'd prefer to use HTML <a> or <img> tags instead of Markdown's link or image syntax, go right ahead. Unlike block-level HTML tags, Markdown syntax is processed within span-level tags. Automatic Escaping for Special Characters In HTML, there are two characters that demand special treatment: < and & . Left angle brackets are used to start tags; ampersands are used to denote HTML entities. If you want to use them as literal characters, you must escape them as entities, e.g. &lt; , and &amp; . Ampersands in particular are bedeviling for web writers. If you want to write about 'AT&T', you need to write ' AT&amp;T '. You even need to escape ampersands within URLs. Thus, if you want to link to: http://images.google.com/images?num=30&q=larry+bird you need to encode the URL as: http://images.google.com/images?num=30&amp;q=larry+bird in your anchor tag href attribute. Needless to say, this is easy to forget, and is probably the single most common source of HTML validation errors in otherwise well-marked-up web sites. Markdown allows you to use these characters naturally, taking care of all the necessary escaping for you. If you use an ampersand as part of an HTML entity, it remains unchanged; otherwise it will be translated into &amp; . So, if you want to include a copyright symbol in your article, you can write: &copy; and Markdown will leave it alone. But if you write: AT&T Markdown will translate it to: AT&amp;T Similarly, because Markdown supports inline HTML , if you use angle brackets as delimiters for HTML tags, Markdown will treat them as such. But if you write: 4 < 5 Markdown will translate it to: 4 &lt; 5 However, inside Markdown code spans and blocks, angle brackets and ampersands are always encoded automatically. This makes it easy to use Markdown to write about HTML code. (As opposed to raw HTML, which is a terrible format for writing about HTML syntax, because every single < and & in your example code needs to be escaped.) Block Elements Paragraphs and Line Breaks A paragraph is simply one or more consecutive lines of text, separated by one or more blank lines. (A blank line is any line that looks like a blank line -- a line containing nothing but spaces or tabs is considered blank.) Normal paragraphs should not be indented with spaces or tabs. The implication of the \"one or more consecutive lines of text\" rule is that Markdown supports \"hard-wrapped\" text paragraphs. This differs significantly from most other text-to-HTML formatters (including Movable Type's \"Convert Line Breaks\" option) which translate every line break character in a paragraph into a <br /> tag. When you do want to insert a <br /> break tag using Markdown, you end a line with two or more spaces, then type return. Yes, this takes a tad more effort to create a <br /> , but a simplistic \"every line break is a <br /> \" rule wouldn't work for Markdown. Markdown's email-style blockquoting and multi-paragraph list items work best -- and look better -- when you format them with hard breaks. Headers Markdown supports two styles of headers, Setext and atx . Setext-style headers are \"underlined\" using equal signs (for first-level headers) and dashes (for second-level headers). For example: This is an H1 ============= This is an H2 ------------- Any number of underlining = 's or - 's will work. Atx-style headers use 1-6 hash characters at the start of the line, corresponding to header levels 1-6. For example: # This is an H1 ## This is an H2 ###### This is an H6 Optionally, you may \"close\" atx-style headers. This is purely cosmetic -- you can use this if you think it looks better. The closing hashes don't even need to match the number of hashes used to open the header. (The number of opening hashes determines the header level.) : # This is an H1 # ## This is an H2 ## ### This is an H3 ###### Blockquotes Markdown uses email-style > characters for blockquoting. If you're familiar with quoting passages of text in an email message, then you know how to create a blockquote in Markdown. It looks best if you hard wrap the text and put a > before every line: > This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, > consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. > Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. > > Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse > id sem consectetuer libero luctus adipiscing. Markdown allows you to be lazy and only put the > before the first line of a hard-wrapped paragraph: > This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. > Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. Blockquotes can be nested (i.e. a blockquote-in-a-blockquote) by adding additional levels of > : > This is the first level of quoting. > > > This is nested blockquote. > > Back to the first level. Blockquotes can contain other Markdown elements, including headers, lists, and code blocks: > ## This is a header. > > 1. This is the first list item. > 2. This is the second list item. > > Here's some example code: > > return shell_exec(\"echo $input | $markdown_script\"); Any decent text editor should make email-style quoting easy. For example, with BBEdit, you can make a selection and choose Increase Quote Level from the Text menu. Lists Markdown supports ordered (numbered) and unordered (bulleted) lists. Unordered lists use asterisks, pluses, and hyphens -- interchangably -- as list markers: * Red * Green * Blue is equivalent to: + Red + Green + Blue and: - Red - Green - Blue Ordered lists use numbers followed by periods: 1. Bird 2. McHale 3. Parish It's important to note that the actual numbers you use to mark the list have no effect on the HTML output Markdown produces. The HTML Markdown produces from the above list is: <ol> <li>Bird</li> <li>McHale</li> <li>Parish</li> </ol> If you instead wrote the list in Markdown like this: 1. Bird 1. McHale 1. Parish or even: 3. Bird 1. McHale 8. Parish you'd get the exact same HTML output. The point is, if you want to, you can use ordinal numbers in your ordered Markdown lists, so that the numbers in your source match the numbers in your published HTML. But if you want to be lazy, you don't have to. If you do use lazy list numbering, however, you should still start the list with the number 1. At some point in the future, Markdown may support starting ordered lists at an arbitrary number. List markers typically start at the left margin, but may be indented by up to three spaces. List markers must be followed by one or more spaces or a tab. To make lists look nice, you can wrap items with hanging indents: * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. But if you want to be lazy, you don't have to: * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. If list items are separated by blank lines, Markdown will wrap the items in <p> tags in the HTML output. For example, this input: * Bird * Magic will turn into: <ul> <li>Bird</li> <li>Magic</li> </ul> But this: * Bird * Magic will turn into: <ul> <li><p>Bird</p></li> <li><p>Magic</p></li> </ul> List items may consist of multiple paragraphs. Each subsequent paragraph in a list item must be indented by either 4 spaces or one tab: 1. This is a list item with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. 2. Suspendisse id sem consectetuer libero luctus adipiscing. It looks nice if you indent every line of the subsequent paragraphs, but here again, Markdown will allow you to be lazy: * This is a list item with two paragraphs. This is the second paragraph in the list item. You're only required to indent the first line. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. * Another item in the same list. To put a blockquote within a list item, the blockquote's > delimiters need to be indented: * A list item with a blockquote: > This is a blockquote > inside a list item. To put a code block within a list item, the code block needs to be indented twice -- 8 spaces or two tabs: * A list item with a code block: <code goes here> It's worth noting that it's possible to trigger an ordered list by accident, by writing something like this: 1986. What a great season. In other words, a number-period-space sequence at the beginning of a line. To avoid this, you can backslash-escape the period: 1986\\. What a great season. Code Blocks Pre-formatted code blocks are used for writing about programming or markup source code. Rather than forming normal paragraphs, the lines of a code block are interpreted literally. Markdown wraps a code block in both <pre> and <code> tags. To produce a code block in Markdown, simply indent every line of the block by at least 4 spaces or 1 tab. For example, given this input: This is a normal paragraph: This is a code block. Markdown will generate: <p>This is a normal paragraph:</p> <pre><code>This is a code block. </code></pre> One level of indentation -- 4 spaces or 1 tab -- is removed from each line of the code block. For example, this: Here is an example of AppleScript: tell application \"Foo\" beep end tell will turn into: <p>Here is an example of AppleScript:</p> <pre><code>tell application \"Foo\" beep end tell </code></pre> A code block continues until it reaches a line that is not indented (or the end of the article). Within a code block, ampersands ( & ) and angle brackets ( < and > ) are automatically converted into HTML entities. This makes it very easy to include example HTML source code using Markdown -- just paste it and indent it, and Markdown will handle the hassle of encoding the ampersands and angle brackets. For example, this: <div class=\"footer\"> &copy; 2004 Foo Corporation </div> will turn into: <pre><code>&lt;div class=\"footer\"&gt; &amp;copy; 2004 Foo Corporation &lt;/div&gt; </code></pre> Regular Markdown syntax is not processed within code blocks. E.g., asterisks are just literal asterisks within a code block. This means it's also easy to use Markdown to write about Markdown's own syntax. Horizontal Rules You can produce a horizontal rule tag ( <hr /> ) by placing three or more hyphens, asterisks, or underscores on a line by themselves. If you wish, you may use spaces between the hyphens or asterisks. Each of the following lines will produce a horizontal rule: * * * *** ***** - - - --------------------------------------- Span Elements Links Markdown supports two style of links: inline and reference . In both styles, the link text is delimited by [square brackets]. To create an inline link, use a set of regular parentheses immediately after the link text's closing square bracket. Inside the parentheses, put the URL where you want the link to point, along with an optional title for the link, surrounded in quotes. For example: This is [an example](http://example.com/ \"Title\") inline link. [This link](http://example.net/) has no title attribute. Will produce: <p>This is <a href=\"http://example.com/\" title=\"Title\"> an example</a> inline link.</p> <p><a href=\"http://example.net/\">This link</a> has no title attribute.</p> If you're referring to a local resource on the same server, you can use relative paths: See my [About](/about/) page for details. Reference-style links use a second set of square brackets, inside which you place a label of your choosing to identify the link: This is [an example][id] reference-style link. You can optionally use a space to separate the sets of brackets: This is [an example] [id] reference-style link. Then, anywhere in the document, you define your link label like this, on a line by itself: [id]: http://example.com/ \"Optional Title Here\" That is: Square brackets containing the link identifier (optionally indented from the left margin using up to three spaces); followed by a colon; followed by one or more spaces (or tabs); followed by the URL for the link; optionally followed by a title attribute for the link, enclosed in double or single quotes, or enclosed in parentheses. The following three link definitions are equivalent: [foo]: http://example.com/ \"Optional Title Here\" [foo]: http://example.com/ 'Optional Title Here' [foo]: http://example.com/ (Optional Title Here) Note: There is a known bug in Markdown.pl 1.0.1 which prevents single quotes from being used to delimit link titles. The link URL may, optionally, be surrounded by angle brackets: [id]: <http://example.com/> \"Optional Title Here\" You can put the title attribute on the next line and use extra spaces or tabs for padding, which tends to look better with longer URLs: [id]: http://example.com/longish/path/to/resource/here \"Optional Title Here\" Link definitions are only used for creating links during Markdown processing, and are stripped from your document in the HTML output. Link definition names may consist of letters, numbers, spaces, and punctuation -- but they are not case sensitive. E.g. these two links: [link text][a] [link text][A] are equivalent. The implicit link name shortcut allows you to omit the name of the link, in which case the link text itself is used as the name. Just use an empty set of square brackets -- e.g., to link the word \"Google\" to the google.com web site, you could simply write: [Google][] And then define the link: [Google]: http://google.com/ Because link names may contain spaces, this shortcut even works for multiple words in the link text: Visit [Daring Fireball][] for more information. And then define the link: [Daring Fireball]: http://daringfireball.net/ Link definitions can be placed anywhere in your Markdown document. I tend to put them immediately after each paragraph in which they're used, but if you want, you can put them all at the end of your document, sort of like footnotes. Here's an example of reference links in action: I get 10 times more traffic from [Google] [1] than from [Yahoo] [2] or [MSN] [3]. [1]: http://google.com/ \"Google\" [2]: http://search.yahoo.com/ \"Yahoo Search\" [3]: http://search.msn.com/ \"MSN Search\" Using the implicit link name shortcut, you could instead write: I get 10 times more traffic from [Google][] than from [Yahoo][] or [MSN][]. [google]: http://google.com/ \"Google\" [yahoo]: http://search.yahoo.com/ \"Yahoo Search\" [msn]: http://search.msn.com/ \"MSN Search\" Both of the above examples will produce the following HTML output: <p>I get 10 times more traffic from <a href=\"http://google.com/\" title=\"Google\">Google</a> than from <a href=\"http://search.yahoo.com/\" title=\"Yahoo Search\">Yahoo</a> or <a href=\"http://search.msn.com/\" title=\"MSN Search\">MSN</a>.</p> For comparison, here is the same paragraph written using Markdown's inline link style: I get 10 times more traffic from [Google](http://google.com/ \"Google\") than from [Yahoo](http://search.yahoo.com/ \"Yahoo Search\") or [MSN](http://search.msn.com/ \"MSN Search\"). The point of reference-style links is not that they're easier to write. The point is that with reference-style links, your document source is vastly more readable. Compare the above examples: using reference-style links, the paragraph itself is only 81 characters long; with inline-style links, it's 176 characters; and as raw HTML, it's 234 characters. In the raw HTML, there's more markup than there is text. With Markdown's reference-style links, a source document much more closely resembles the final output, as rendered in a browser. By allowing you to move the markup-related metadata out of the paragraph, you can add links without interrupting the narrative flow of your prose. Emphasis Markdown treats asterisks ( * ) and underscores ( _ ) as indicators of emphasis. Text wrapped with one * or _ will be wrapped with an HTML <em> tag; double * 's or _ 's will be wrapped with an HTML <strong> tag. E.g., this input: *single asterisks* _single underscores_ **double asterisks** __double underscores__ will produce: <em>single asterisks</em> <em>single underscores</em> <strong>double asterisks</strong> <strong>double underscores</strong> You can use whichever style you prefer; the lone restriction is that the same character must be used to open and close an emphasis span. Emphasis can be used in the middle of a word: un*frigging*believable But if you surround an * or _ with spaces, it'll be treated as a literal asterisk or underscore. To produce a literal asterisk or underscore at a position where it would otherwise be used as an emphasis delimiter, you can backslash escape it: \\*this text is surrounded by literal asterisks\\* Code To indicate a span of code, wrap it with backtick quotes ( ` ). Unlike a pre-formatted code block, a code span indicates code within a normal paragraph. For example: Use the `printf()` function. will produce: <p>Use the <code>printf()</code> function.</p> To include a literal backtick character within a code span, you can use multiple backticks as the opening and closing delimiters: ``There is a literal backtick (`) here.`` which will produce this: <p><code>There is a literal backtick (`) here.</code></p> The backtick delimiters surrounding a code span may include spaces -- one after the opening, one before the closing. This allows you to place literal backtick characters at the beginning or end of a code span: A single backtick in a code span: `` ` `` A backtick-delimited string in a code span: `` `foo` `` will produce: <p>A single backtick in a code span: <code>`</code></p> <p>A backtick-delimited string in a code span: <code>`foo`</code></p> With a code span, ampersands and angle brackets are encoded as HTML entities automatically, which makes it easy to include example HTML tags. Markdown will turn this: Please don't use any `<blink>` tags. into: <p>Please don't use any <code>&lt;blink&gt;</code> tags.</p> You can write this: `&#8212;` is the decimal-encoded equivalent of `&mdash;`. to produce: <p><code>&amp;#8212;</code> is the decimal-encoded equivalent of <code>&amp;mdash;</code>.</p> Images Admittedly, it's fairly difficult to devise a \"natural\" syntax for placing images into a plain text document format. Markdown uses an image syntax that is intended to resemble the syntax for links, allowing for two styles: inline and reference . Inline image syntax looks like this: ![Alt text](/path/to/img.jpg) ![Alt text](/path/to/img.jpg \"Optional title\") That is: An exclamation mark: ! ; followed by a set of square brackets, containing the alt attribute text for the image; followed by a set of parentheses, containing the URL or path to the image, and an optional title attribute enclosed in double or single quotes. Reference-style image syntax looks like this: ![Alt text][id] Where \"id\" is the name of a defined image reference. Image references are defined using syntax identical to link references: [id]: url/to/image \"Optional title attribute\" As of this writing, Markdown has no syntax for specifying the dimensions of an image; if this is important to you, you can simply use regular HTML <img> tags. Miscellaneous Automatic Links Markdown supports a shortcut style for creating \"automatic\" links for URLs and email addresses: simply surround the URL or email address with angle brackets. What this means is that if you want to show the actual text of a URL or email address, and also have it be a clickable link, you can do this: <http://example.com/> Markdown will turn this into: <a href=\"http://example.com/\">http://example.com/</a> Automatic links for email addresses work similarly, except that Markdown will also perform a bit of randomized decimal and hex entity-encoding to help obscure your address from address-harvesting spambots. For example, Markdown will turn this: <address@example.com> into something like this: <a href=\"&#x6D;&#x61;i&#x6C;&#x74;&#x6F;:&#x61;&#x64;&#x64;&#x72;&#x65; &#115;&#115;&#64;&#101;&#120;&#x61;&#109;&#x70;&#x6C;e&#x2E;&#99;&#111; &#109;\">&#x61;&#x64;&#x64;&#x72;&#x65;&#115;&#115;&#64;&#101;&#120;&#x61; &#109;&#x70;&#x6C;e&#x2E;&#99;&#111;&#109;</a> which will render in a browser as a clickable link to \"address@example.com\". (This sort of entity-encoding trick will indeed fool many, if not most, address-harvesting bots, but it definitely won't fool all of them. It's better than nothing, but an address published in this way will probably eventually start receiving spam.) Backslash Escapes Markdown allows you to use backslash escapes to generate literal characters which would otherwise have special meaning in Markdown's formatting syntax. For example, if you wanted to surround a word with literal asterisks (instead of an HTML <em> tag), you can use backslashes before the asterisks, like this: \\*literal asterisks\\* Markdown provides backslash escapes for the following characters: \\ backslash ` backtick * asterisk _ underscore {} curly braces [] square brackets () parentheses # hash mark + plus sign - minus sign (hyphen) . dot ! exclamation mark","title":"MarkdownSyntax"},{"location":"Overarching_Guidance/","text":"5. Overarching Guidance Table of Contents Overview Philosophy Inline HTML Automatic Escaping for Special Characters Block Elements Paragraphs and Line Breaks Headers Blockquotes Lists Code Blocks Horizontal Rules Span Elements Links Emphasis Code Images Miscellaneous Backslash Escapes Automatic Links","title":"5. Overarching Guidance"},{"location":"Overarching_Guidance/#5-overarching-guidance","text":"","title":"5. Overarching Guidance"},{"location":"Overarching_Guidance/#table-of-contents","text":"Overview Philosophy Inline HTML Automatic Escaping for Special Characters Block Elements Paragraphs and Line Breaks Headers Blockquotes Lists Code Blocks Horizontal Rules Span Elements Links Emphasis Code Images Miscellaneous Backslash Escapes Automatic Links","title":"Table of Contents"},{"location":"Solution_Architecture/PDFtest/","text":"Testing the embedding of a PDF Process map PDF Internet Ingress Pattern","title":"Testing the embedding of a PDF"},{"location":"Solution_Architecture/PDFtest/#testing-the-embedding-of-a-pdf","text":"Process map PDF Internet Ingress Pattern","title":"Testing the embedding of a PDF"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/","text":"Public / Private API Guidance Guiding Principles Application Programming Interfaces (APIs) are a critical part of almost any application design. Guidance to date for the implementation of APIs in AWS, has been inconsistent and poorly aligned with AWS best practices. This guidance will address those issues as it relates to Public APIs as well as provide guidance on securing Public APIs to make them private. Goals Provide architecture guidance on approved patterns for implementing Public and Private APIs in AWS including: * Guidance for using both AWS CloudFront and Akamai as the Content Delivery Network (CDN). * Guidance for securing Public APIs to make them Private. * Options for implementing authentication and the role authentication plays in simplifying API implementation. * Architecture Controls that specify required implementation details Out of Scope Configuration of Akamai services Configuration of Authentication services outside the specification to use Strong Authentication (e.g. MFA) as a means to secure public APIs. Approved Patterns The following Architecture Patterns are approved for use for Public and Private APIs where the underlying API service runs in a SWA AWS environment. Public APIs Public APIs should be those APIs that are read-only and only provide access to data deemed Public by the Data Classification guidelines. Public API using CloudFront For Public API services running entirely in AWS, those services should use the following architecture design. CloudFront provides a Public API global endpoint. CloudFront is integrated with AWS Shield Advanced. Shield Advanced is configured to allow the AWS DDoS Response Team to detect Distributed Denial of Service attacks and notify SWA. CloudFront is also integrated with AWS Web Application Firewall (WAF) and the appropriate firewall rulesets have been loaded. Examples include but are not limited to: AWS Managed Baseline Rule Groups CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to. Public API using Akamai For Public API services using Akamai to provide the global API endpoint, the following architecture design should be used. Akamai provides the Global API endpoint and provides multiple API services (e.g. Bot Management, DDoS mitigation services, etc). Akamai connects directly to AWS CloudFront, and AWS WAF limits connections to the CloudFront Public API endpoint to sources originating from Akamai. The AWS WAF does not need to be configured to leverage any other managed rulesets. Shield Advanced is still configured to perform DDoS mitigation, similar to the Public API pattern above. CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to. Private APIs Private APIs are those APIs that either provide access to non-public SWA data or are operational in nature. If the API facilitates a change in state to a SWA system, then the API is considered Private and one of the following patterns must be used. Restricting access with Authentication The preferred pattern to secure Private APIs, is to enable strong authentication. The authentication used must be considered to be strong authentication. * Examples of strong authentication: * Multi-Factor Authentication * OAuth-based Authentication * Examples that do NOT qualify as strong authentication: * Username and password * Certificate based mutual authentication CloudFront provides a Public API global endpoint. CloudFront is integrated with AWS Shield Advanced. Shield Advanced is configured to allow the AWS DDoS Response Team to detect Distributed Denial of Service attacks and notify SWA. CloudFront is also integrated with AWS Web Application Firewall (WAF) and the appropriate firewall rulesets have been loaded. Examples include but are not limited to: AWS Managed Baseline Rule Groups CloudFront is leveraging Lambda@Edge to inspect the headers for a previously successful authentication session. If the appropriate header is not found and validated, then the client is redirected to the SWA Enterprise Ping instance to be authenticated. Once authentication is complete, CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to. API Gateway has an AWS IAM resource policy attached to it to only allow connections from the specific CloudFront origin. API Service has an AWS IAM resource policy attached to it to only allow connections from the specific API Gateway configured for the service. Restricting access with AWS WAF If strong authentication cannot be used, then a pattern similar to the Public API with CloudFront can be used, provided the WAF rules are configured to restrict access to SWA internal networks and SWA public IP addresses. CloudFront provides a Public API global endpoint. CloudFront is integrated with AWS Shield Advanced. Shield Advanced is configured to allow the AWS DDoS Response Team to detect Distributed Denial of Service attacks and notify SWA. CloudFront is integrated with AWS Web Application Firewall (WAF): Specific WAF rules have been loaded to restrict the Public API to SWA internal and public IP addresses Additional appropriate firewall rulesets have been loaded. Examples include but are not limited to: AWS Managed Baseline Rule Groups CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to. Example Single Page App Below is an example architecture for a Single Page Web Application. In this architecture, the Private API with MFA pattern has been extended to include static content hosting from S3. Summary In summary, this architecture guidance for Public and Private APIs attempts to simplify the number of patterns around common use of AWS service aligned to AWS best practices. Value is placed on reusability, simplicity, and security. This guidance should be revisited regularly to ensure these principals continue to be met. Architecture Controls Control ID Control Description CLOUDAPI-01 Public APIs must only expose SWA data classified as \"PUBLIC\" CLOUDAPI-02 CloudFront must be used as the API endpoint that users and services will interact with CLOUDAPI-03 CloudFront must require authentication for Private APIs CLOUDAPI-04 Where strong authentication using multi-factor cannot be used, WAF rules must be used to restrict access to SWA internal networks and SWA public IP addresses CLOUDAPI-05 API Gateway must restrict access to source from CloudFront CLOUDAPI-06 API services must restrict access to source from API Gateway CLOUDAPI-07 CloudFront must be configured to be integrated with Shield Advanced CLOUDAPI-08 Shield Advanced must minimally be configured to allow AWS DDoS Response Team (DRT) access to logs and must be configured with SWA contact info for DDoS event notification CLOUDAPI-09 Where Akamai acts as the Content Delivery Network (CDN), CloudFront must be configured to only allow connections from Akamai","title":"Public / Private API Guidance"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#public-private-api-guidance","text":"","title":"Public / Private API Guidance"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#guiding-principles","text":"Application Programming Interfaces (APIs) are a critical part of almost any application design. Guidance to date for the implementation of APIs in AWS, has been inconsistent and poorly aligned with AWS best practices. This guidance will address those issues as it relates to Public APIs as well as provide guidance on securing Public APIs to make them private.","title":"Guiding Principles"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#goals","text":"Provide architecture guidance on approved patterns for implementing Public and Private APIs in AWS including: * Guidance for using both AWS CloudFront and Akamai as the Content Delivery Network (CDN). * Guidance for securing Public APIs to make them Private. * Options for implementing authentication and the role authentication plays in simplifying API implementation. * Architecture Controls that specify required implementation details","title":"Goals"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#out-of-scope","text":"Configuration of Akamai services Configuration of Authentication services outside the specification to use Strong Authentication (e.g. MFA) as a means to secure public APIs.","title":"Out of Scope"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#approved-patterns","text":"The following Architecture Patterns are approved for use for Public and Private APIs where the underlying API service runs in a SWA AWS environment.","title":"Approved Patterns"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#public-apis","text":"Public APIs should be those APIs that are read-only and only provide access to data deemed Public by the Data Classification guidelines.","title":"Public APIs"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#public-api-using-cloudfront","text":"For Public API services running entirely in AWS, those services should use the following architecture design. CloudFront provides a Public API global endpoint. CloudFront is integrated with AWS Shield Advanced. Shield Advanced is configured to allow the AWS DDoS Response Team to detect Distributed Denial of Service attacks and notify SWA. CloudFront is also integrated with AWS Web Application Firewall (WAF) and the appropriate firewall rulesets have been loaded. Examples include but are not limited to: AWS Managed Baseline Rule Groups CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to.","title":"Public API using CloudFront"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#public-api-using-akamai","text":"For Public API services using Akamai to provide the global API endpoint, the following architecture design should be used. Akamai provides the Global API endpoint and provides multiple API services (e.g. Bot Management, DDoS mitigation services, etc). Akamai connects directly to AWS CloudFront, and AWS WAF limits connections to the CloudFront Public API endpoint to sources originating from Akamai. The AWS WAF does not need to be configured to leverage any other managed rulesets. Shield Advanced is still configured to perform DDoS mitigation, similar to the Public API pattern above. CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to.","title":"Public API using Akamai"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#private-apis","text":"Private APIs are those APIs that either provide access to non-public SWA data or are operational in nature. If the API facilitates a change in state to a SWA system, then the API is considered Private and one of the following patterns must be used.","title":"Private APIs"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#restricting-access-with-authentication","text":"The preferred pattern to secure Private APIs, is to enable strong authentication. The authentication used must be considered to be strong authentication. * Examples of strong authentication: * Multi-Factor Authentication * OAuth-based Authentication * Examples that do NOT qualify as strong authentication: * Username and password * Certificate based mutual authentication CloudFront provides a Public API global endpoint. CloudFront is integrated with AWS Shield Advanced. Shield Advanced is configured to allow the AWS DDoS Response Team to detect Distributed Denial of Service attacks and notify SWA. CloudFront is also integrated with AWS Web Application Firewall (WAF) and the appropriate firewall rulesets have been loaded. Examples include but are not limited to: AWS Managed Baseline Rule Groups CloudFront is leveraging Lambda@Edge to inspect the headers for a previously successful authentication session. If the appropriate header is not found and validated, then the client is redirected to the SWA Enterprise Ping instance to be authenticated. Once authentication is complete, CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to. API Gateway has an AWS IAM resource policy attached to it to only allow connections from the specific CloudFront origin. API Service has an AWS IAM resource policy attached to it to only allow connections from the specific API Gateway configured for the service.","title":"Restricting access with Authentication"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#restricting-access-with-aws-waf","text":"If strong authentication cannot be used, then a pattern similar to the Public API with CloudFront can be used, provided the WAF rules are configured to restrict access to SWA internal networks and SWA public IP addresses. CloudFront provides a Public API global endpoint. CloudFront is integrated with AWS Shield Advanced. Shield Advanced is configured to allow the AWS DDoS Response Team to detect Distributed Denial of Service attacks and notify SWA. CloudFront is integrated with AWS Web Application Firewall (WAF): Specific WAF rules have been loaded to restrict the Public API to SWA internal and public IP addresses Additional appropriate firewall rulesets have been loaded. Examples include but are not limited to: AWS Managed Baseline Rule Groups CloudFront uses Route 53 to lookup the most appropriate API Gateway endpoint to forward API requests to. Route 53 leverages health checks and Route 53 Application Recovery Controller to determine which API Gateway endpoint to direct API requests to.","title":"Restricting access with AWS WAF"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#example-single-page-app","text":"Below is an example architecture for a Single Page Web Application. In this architecture, the Private API with MFA pattern has been extended to include static content hosting from S3.","title":"Example Single Page App"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#summary","text":"In summary, this architecture guidance for Public and Private APIs attempts to simplify the number of patterns around common use of AWS service aligned to AWS best practices. Value is placed on reusability, simplicity, and security. This guidance should be revisited regularly to ensure these principals continue to be met.","title":"Summary"},{"location":"Technical_Architecture/API%20Guidance/Public_API_Guidance/#architecture-controls","text":"Control ID Control Description CLOUDAPI-01 Public APIs must only expose SWA data classified as \"PUBLIC\" CLOUDAPI-02 CloudFront must be used as the API endpoint that users and services will interact with CLOUDAPI-03 CloudFront must require authentication for Private APIs CLOUDAPI-04 Where strong authentication using multi-factor cannot be used, WAF rules must be used to restrict access to SWA internal networks and SWA public IP addresses CLOUDAPI-05 API Gateway must restrict access to source from CloudFront CLOUDAPI-06 API services must restrict access to source from API Gateway CLOUDAPI-07 CloudFront must be configured to be integrated with Shield Advanced CLOUDAPI-08 Shield Advanced must minimally be configured to allow AWS DDoS Response Team (DRT) access to logs and must be configured with SWA contact info for DDoS event notification CLOUDAPI-09 Where Akamai acts as the Content Delivery Network (CDN), CloudFront must be configured to only allow connections from Akamai","title":"Architecture Controls"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/","text":"Cloud Resiliency Guidance Cloud Resiliency Guidance Introduction Guiding Principles Goals & Objectives Document Scope Out of Scope Resiliency Capabilities Overview AWS Global Infrastructure Design Availability Zones AWS Regions AWS Service Fault Domains Component Scaling Overview of Key Services Route 53 Route 53 Control Plane vs. Data Plane Health Checks Service Discovery Application Load Balancing Global Load Balancing Potential Recovery Limitations API Call Throttling Availability of EC2 instance types Service Quotas State Management Service Recovery Testing Resiliency Requirements & Patterns Component Resiliency Resiliency Patterns Globally Resilient Key Requirements for Globally Resilient workloads Example Globally Resilient Single Page App (SPA) Regionally Resilient Key Requirements for Regionally Resilient workloads Example Single Page App (SPA) Example Service to Service Example Regionally Resilient Kubernetes Application Regionally Resilient with Failover Key Requirements for Regionally Resilient (Manual Failover) workloads Single Region with Standby Key Requirements for Single Region with Standby workloads Single Region Key Requirements for Single Region workloads Sound Recovery Practices Best practices for service recovery Recommended corresponding Architecture Practices Design Reviews Design Approval Architecture Exceptions Introduction Cloud resiliency refers to the architecture design practices that contribute to applications, running in AWS, that are resilient to service disrupting events. Service disrupting events can include: * Regional outages * Service instability * Platform instability * Control plane instability * Connectivity issues Guiding Principles Southwest Airlines critical business and operations functions depend on applications running in cloud environments hosted by AWS. In order to satisfy Southwest business function requirements and meet availability and recoverability targets, specific guidance and reviews must be in place to support positive resiliency outcomes. Recently, there have been service disruptions, within the AWS platforms and infrastructure, that have negatively impacted technology services that support Southwest Airlines business and operations. Analysis of these events has revealed underlying design flaws that should be addressed in existing designs and new designs. Goals & Objectives The objectives for this guidance on resiliency are to: 1. Evaluate and understand potential issues and capabilities that contribute or detract from the resiliency of applications running in AWS 2. Provide guidance for resiliency that maps to desired business outcomes 3. Establish architectural patterns that clearly describe how applications can be designed to avoid unnecessary outages 4. Describe best practices for implementing a service recovery and testing program 4. Recommended changes to architecture practices to enhance focus on application resiliency Document Scope Out of Scope The following topics are considered out of scope for this Architecture Design Document: * While health monitoring may be covered as a topic to manage component failures, general observability and dashboarding of application health is outside the scope of this document. * The resiliency of data platforms, including operational, analytical, and streaming data platforms will be covered in Cloud Data Resiliency Guidance. Resiliency Capabilities Overview The following capabilities are relevant to resiliency in cloud. A brief description and discussion of relevance is included, but full documentation of these capabilities is beyond the scope of this document. AWS Global Infrastructure Design AWS provides globally available infrastructure for use by their customers. That infrastructure is comprised of data centers, Availability Zones (AZ)s, and Regions. The most up to date information on AZs and Regions can always be found on the AWS Website . Availability Zones An Availability Zone (AZ) is one or more discrete data centers with redundant power, networking, and connectivity in an AWS Region. For context, an AZ is the equivalent of the SWA SDC or WNDC data center. AWS Regions AWS has the concept of a Region, which is a physical location around the world where they cluster data centers. Each group of logical data centers are referenced as an Availability Zone. Each AWS Region consists of multiple, isolated, and physically separate AZs within a geographic area. AWS Service Fault Domains Solution resiliency is a byproduct of individual service resiliency. The first aspect of any solution that should be examined is the resiliency of each component that the solution is comprised of. The table below describes patterns of component resiliency that are used throughout this guidance document. Service Domain Description Examples Global These services are available even if a Region fails Route 53, IAM, CloudFront Region These services are available even if an Availability Zone fails S3, KMS, Lambda Availability Zone These services will fail if an Availability Zone fails. Additional steps should be taken to provide for regional resiliency EC2, EBS, EFS Instance An instance may fail if a platform within an Availability Zone fails. Additional steps should be taken to examine and understand the availability and recovery characteristics of the platform that the instance runs within. EKS, Container Component Scaling Scaling is a key consideration when planning for application and component level resiliency. Scaling considerations need to balance the need to control costs with those of ensuring resiliency in the event of a failure. For services with critical business functions, (Tier 0, Tier 1), scaling events should be avoided during a failover event, as contention for Control Plane functionality and resources can cause scaling events to fail. For these reasons it is important to tailor the scaling of application components to the overall desired availability. The table below maps component level scaling to the component resiliency patterns above. Component Resiliency Scaling Description Global Component - Scaling managed by AWS Active / Active Component - Components scaled to support 100% of the application workload in a single region Active / Passive with Automated Recovery - Active region scaled to support 100% of the application workload - Passive region is also scaled to support 100% of the application workload. This prevents the passive region from failing to service requests adequately during a failover scenario. Active / Passive with Manual Recovery - Active region scaled to support 100% of the application workload - Passive region is also scaled to support 100% of the application workload. This prevents the passive region from failing to service requests adequately during a failover scenario. Active / Standby - Active region scaled to support 100% of the application workload Single Region - Single region scaled to support 100% of the application workload Overview of Key Services In addition to the AWS Infrastructure Design, there are key AWS services and capabilities that, when used correctly, can contribute to the resiliency of applications. Route 53 Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) service. Amazon Route 53 effectively connects user requests to infrastructure running in AWS and can also be used to route users to infrastructure outside of AWS. Below are features of Route53 that are relevant for resiliency and failover: DNS Health Checks \u2013 Allows you to monitor the health of your resources such as web servers and email servers. You can optionally configure Amazon CloudWatch alarms for your health checks, so that you receive notification when a resource becomes unavailable. DNS Failover - Along with DNS Health checks, you can configure DNS failover so that Route 53 will route your traffic from an unhealthy resource to a healthy resource. You can choose the active-active failover configuration when you want all of your resources to be available the majority of the time or active-passive when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. Traffic Flow - Makes it easy for you to manage traffic globally through a variety of routing policies, including Latency Based Routing, Geo DNS, Geoproximity, and Weighted Round Robin\u2014all of which can be combined with DNS Failover in order to enable a variety of low-latency, fault-tolerant architectures. For more information on routing policies see AWS Routing Policies Using Amazon Route 53 Traffic Flow\u2019s simple visual editor, you can easily manage how your end-users are routed to your application\u2019s endpoints\u2014whether in a single AWS region or distributed around the globe. Application Recover Controller - Gives you insights into whether your applications and resources are ready for recovery, and helps you manage and coordinate failover using readiness check and routing control features Route 53 Control Plane vs. Data Plane Understanding the different service capabilities of Route 53 and how those capabilities leverage the control plane vs the data plane can be crucial to understanding overall resiliency of Route 53 and how the it will respond in failure and recovery situations. For example, you can rely on the Amazon Route 53 data plane to reliably route DNS queries based on health checks. Updating Route 53 routing policies, DNS weights, and records, however, uses the control plane, and cannot be relied upon for recovery. When implementing recovery or mitigation responses to potentially resiliency-impacting events, using control plane operations can lower the overall resiliency of your architecture. Control Plane The control plane is used to configure services. For Route 53, the control plane has a lower availability design goal than the data plane. The control plane should not be relied upon for service recovery and application resiliency for highly available services in tiers 1 and 2. Data Plane The data plane is used to deliver services. The data plane maintains a much higher uptime commitment. The data plane should be the method by which services instrument high availability. Route 53 health checks are an example of a data plane capability that can aid in application services maintaining high availability. Health Checks Health checks are a way of asking a service whether or not it is capable of performing work successfully. Examples of health checks include, but are not limited to: Health checks integrated into Route 53 DNS services, which validate underlying service health Load balancers polling services periodically to determine which servers it is safe to direct traffic to. A service that checks its own health before pulling messages off a queue. Monitoring agents that determine the health of a service and raise events or remove a service from service discovery in the event of service degradation. Health checks are a critical part of the design of resilient solutions, as they anticipate and isolate failures, thereby preserving service availability. Health checks need to be designed to mitigate component level failures, but must also take into account the design of the entire solution. Service Discovery Service Discovery is the process of dynamically detecting services available on a network. Resiliency of an application can be enhanced through the use of service discovery. Two models of service discovery exist, server-side and client-side service discovery. In a server-side service discovery model, the server updates its availability with a load-balancer, DNS, or similar system to route traffic to available service endpoints. In a client-side service discovery model, the client queries a service registry to determine available service endpoints and connects to the appropriate one. A full discussion of service discovery is beyond the scope of this design document, and will require a separate design. Application Load Balancing Application Load Balancers allow for the distribution of incoming requests across service endpoints, while allowing for intelligent health checks, and load distribution algorithms. A limitation of AWS Application Load Balancers is that it they are a regional service, and can only control automated failover across services running in more than one Availability Zone. Global Load Balancing Global load balancing refers to the ability to distribute service requests across a global distribution of service endpoints. Global load balancing in AWS is managed by Route 53 and includes a variety of routing policies, including Latency Based Routing, Geo DNS, Geoproximity, and Weighted Round Robin\u2014all of which can be combined with DNS Failover in order to enable a variety of low-latency, fault-tolerant architectures. Potential Recovery Limitations In the event of a component or application recovery, certain conditions can occur that can limit the ability of the system to self-heal or limit manual recovery efforts. It is important to understand these limitations and design the application and component recovery accordingly. API Call Throttling Especially in regional recovery scenarios, API throttling or contention, can limit the ability for even automated recovery functions to successfully recover services to a functioning state. This can be further exacerbated when attempting to use the Control Plane for recovery, where overall availability may not match SWA recovery requirements. Availability of EC2 instance types In rare circumstances, although increased potential exists during a regional outage, contention for specific EC2 instance types can result in the inability to rapidly provision new instances. Like API calls, this can be exacerbated by Control Plane issues that slow down or prevent instance provisioning events. For this reason, scaling and instance provisioning should be tailored to the availability expectations of the application. Please refer to the Component Scaling section of this guidance. Service Quotas Service quotas can impact application availability and should be managed using a process that balances cost implications of escalating services quotas yet mitigates potential impacts of restricting application scaling or performance. In particular, service quotas can be particularly impactful in failover events where there is increased potential for exceeding currently defined service limits or service quotas. AWS Service Quotas best practices for reliability, from the AWS Well-Architected Framework can be found here, and include: * Aware of service quotas and constraints: You are aware of your default quotas and quota increase requests for your workload architecture. You additionally know which resource constraints, such as disk or network, are potentially impactful. * Manage service quotas across accounts and regions: If you are using multiple AWS accounts or AWS Regions, ensure that you request the appropriate quotas in all environments in which your production workloads run. * Accommodate fixed service quotas and constraints through architecture: Be aware of unchangeable service quotas and physical resources, and architect to prevent these from impacting reliability. * Monitor and manage quotas: Evaluate your potential usage and increase your quotas appropriately allowing for planned growth in usage. * Automate quota management: Implement tools to alert you when thresholds are being approached. By using AWS Service Quotas APIs, you can automate quota increase requests. * Ensure that a sufficient gap exists between the current quotas and the maximum usage to accommodate failover: When a resource fails, it may still be counted against quotas until it is successfully terminated. Ensure that your quotas cover the overlap of all failed resources with replacements before the failed resources are terminated. You should consider an Availability Zone failure when calculating this gap. State Management A thorough understanding of the application's dependence on state is necessary to thoroughly understand the ability to successfully recover the application and meet the Recovery Point Objectives of the application. Recovery from failures, including the restoration of state is something that must be tested. Service Recovery Testing The process of full service recovery must be documented and tested regularly. Additionally, depending on business criticality, Teams should have the appropriate level of automated recovery in place. The table under Resiliency Requirements below describes service recovery and testing requirements. These tests should be run as part of the certification and deployment process, but also run under load, where real-world transactions will stress and expose unexpected situations. Resiliency Requirements & Patterns Component Resiliency Components running only in a single Availability Zone can often times be designed to have a regional or even global resiliency through different configuration patterns. The table below describes patterns of component resiliency that are used throughout this guidance document. Option Description Global Component - Regional resiliency managed by AWS. - Expected to be globally available, and should be used preferentially. - Care must be taken to understand what aspects of a global component, like Route 53, is actually globally available. Active / Active Component - Component service requests are sent to all regions and can be processed independent of other regions. - Care must be taken to configure these services correctly and to understand any required state management. (Either does not depend on state, can use an eventual consistency model, or uses a synchronous replication of state.) -Care must also be taken to understand event sequencing requirements, which can cause transactional or data integrity issues within the larger solution context. Active / Passive Component with Automated Recovery - Component service requests are sent to only one region at a time - Deep health checks are configured to assess regional component health, and recovery automated in the AWS data plane - Component recovery and failback from component recovery must be thoroughly tested to eliminate any issues with data integrity Active / Passive Component with Manual Recovery - Component service requests are sent to only one region - Health checks are configured to assess regional component health - Recovery mechanisms are in place that can be executed without use of the AWS control plane Active / Standby Component - Component service requests are sent to only one region - Health checks are in place to assess regional component health - Processes are in place and have been tested to active standby region components Single Region - Component service requests are sent to only one region - Regional outages will result in loss of service until the region is recovered Resiliency Patterns The following resiliency patterns describe the high level characteristics as well as supported Application recovery Hierarchy tiers. Further details can be found within the following documentation of each resiliency pattern, including examples. Resiliency Pattern Characteristics Supported ARH Tiers Globally Resilient - Application components run globally and are resilient to issues impacting more than one region - Service recovery is automatic and self-healing Tier 0, Tier 1 (provided ltency requirements of the application can be met.) Regionally Resilient - Application components run active / active across 2 regions and are resilient to issues impacting a single region - Data is synchronous across regions - Health checks proactively monitor for failed components and isolate failures - Service recovery is automatic and self-healing Tier 0, Tier 1 Regionally Resilient with Failover - Application components run active / passive across 2 regions - Data replication may be asynchronous - Health checks identify failed components, but recovery may be manual in some or all cases Tier 2 Single Region with Standby - Application components run active / standby across 2 regions - Data replication may be asynchronous - Health checks identify failures - Service recovery requires starting the application in a standby region Tier 3+ Single Region - Application components run in a single region - Failures are detected by health checks - Services are recovered once the region has been restored to full operations Tier 4 Globally Resilient Globally resilient architectures extend the Regionally Resilient pattern to include global dispersion of workloads. This means that globally resilient applications are deployed and active in at least 3 regions, across 2 continents, and can withstand failures in more than one region. Component resiliency pattern Preference Global component Allowed Active / Active component Allowed, with design review Active / Passive with automated health check and recovery Not Allowed Active / Passive with manual recovery Not Allowed Active / Standby Not Allowed Single Region Not Allowed Key Requirements for Globally Resilient workloads The following table shows key requirements for Globally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 3 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Require serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and must leverage automated failover to redirect traffic away from the failed component. | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform | Example Globally Resilient Single Page App (SPA) Integrations between components is a critical aspect of achieving true regional resilience.The diagram above depicts a basic pattern for Single Page Apps, with static content being served from S3, and dynamic content being served from one or more lambdas. CloudFront and Route 53 manage traffic routing avoiding any simgle point of failure. Traffic routing at each step is dynamic and can be routed to least latent and available services. * The pattern above leverages CloudFront, Route 53 , S3 replication and API Gateway to create a highly resilient solution. * All services being used have health checks in place to dynamically route traffic to all regions. * Services like lambda and S3 are managed by AWS and do require explicit scaling configurations. Regionally Resilient Regionally resilient architectures attempt to eliminate any single failure points within an application across at least 2 regions. Designs need to examine each component to ensure that regional resilience is accounted for. The following component resiliency patterns can be leveraged to design for regionally resilient solutions. Component resiliency pattern Preference Global component Preferred Active / Active component Preferred Active / Passive with automated health check and recovery Allowed Active / Passive with manual recovery Not Allowed Active / Standby Not Allowed Single Region Not Allowed Key Requirements for Regionally Resilient workloads The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and automatically redirect traffic away from the failed component . | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform | Example Single Page App (SPA) Integrations between components is a critical aspect of achieving true regional resilience.The diagram above depicts a basic pattern for Single Page Apps, with static content being served from S3, and dynamic content being served from one or more lambdas. Key guidance for Regionally Resilient Single Page Apps: * CloudFront and Route 53 manage traffic routing avoiding any simgle point of failure. Traffic routing at each step is dynamic and can be routed to least latent and available services. * The pattern above leverages CloudFront, Route 53 , S3 replication and API Gateway to create a highly resilient solution. * All services being used have health checks in place to dynamically route traffic to both regions. * Services like lambda and S3 are managed by AWS and do require explicit scaling configurations. Example Service to Service Key guidance for Regionally Resilient Service APIs: * CloudFront and Route 53 manage traffic routing avoiding any simgle point of failure. Traffic routing at each step is dynamic and can be routed to least latent and available services. * The pattern above leverages CloudFront, Route 53 , and API Gateway to create a highly resilient solution. * All services being used have health checks in place to dynamically route traffic to both regions. * Services like lambda are managed by AWS and do require explicit scaling configurations. Example Regionally Resilient Kubernetes Application Key points for Regionally Resilient EKS container based applications: * EKS clusters exist within a single region and cannot span regions. Each region will have a separate EKS cluster. * EKS cluster nodes should be distributed evenly across at least 3 AZs * Application services, running as containers within EKS, should be evenly distributed across EKS cluster nodes and at least 3 AZs * Route 53 health checks determine health of each region and distribute traffic accordingly * Health monitoring within EKS isolates and restarts unhealth nodes and container workloads, maintaining a minimum of 3 healthy AZs at all times * For Regionally Resilient workloads, capacity of each regional EKS cluster should be scaled to support 100% of the application workload at all times. Scaling of workloads should not be part of the recovery design for the Regionally Resilient pattern, as resource contention and control plane issues can hinder scaling events during regional recovery activities. Regionally Resilient with Failover Description Component resiliency pattern Preference Global component Preferred Active / Active component Preferred Active / Passive with automated health check and recovery Preferred Active / Passive with manual recovery Allowed Active / Standby Not Allowed Single Region Not Allowed Key Requirements for Regionally Resilient (Manual Failover) workloads The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and may leverage automated failover to redirect traffic away from the failed component. | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform | Single Region with Standby Description Component resiliency pattern Preference Global component Preferred Active / Active component Allowed Active / Passive with automated health check and recovery Allowed Active / Passive with manual recovery Preferred Active / Standby Allowed Single Region Not Allowed Key Requirements for Single Region with Standby workloads The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and automatically redirect traffic away from the failed component . | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform | Single Region Description Component resiliency pattern Preference Global component Allowed Active / Active component Not Allowed Active / Passive with automated health check and recovery Not Allowed Active / Passive with manual recovery Not Allowed Active / Standby Not Allowed Single Region Preferred Key Requirements for Single Region workloads The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and automatically redirect traffic away from the failed component . | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform | Sound Recovery Practices Best practices for service recovery Service preference: When designing applications, prefer AWS Global and AWS Regional services to minimize recovery effort and control scaling costs. Prefer serverless: This applies to compute workloads as well. Service design should prefer serverless designs over alternatives, as serverless designs require externalizing state, eliminate scaling issues, and Start with components: Start by understanding how each component will behave in a failure scenario, and understand and document recovery processes. Understand data resiliency: Data resiliency is a key part of understanding the ability to effectively recover any service. Key data dependencies, like the data consistency model, must be thoroughly understood. Data replication, backup, and recovery processes play a critical role in overall system recovery. Separate Data Resiliency guidance will address the specific aspects of data resiliency. Prefer automation: Service recovery automaton is a key non-functional requirement for services and should be part of the architecture design process. a. For known use cases, automate intelligent and deep health checks that uncover service issues and isolate failures. b. To raise overall service availability, extend automation to self-healing activities that remove human interaction. Required for some resiliency patterns . Test often: Test failure scenarios frequently. Build automated integration tests that validate heath checks and recovery solutions. Perform thought experiments to uncover new scenarios that may lead to failures. Assume the worst: Assume everything will fail eventually and be sure that those failure scenarios have been tested and behave as expected. Recommended corresponding Architecture Practices Design Reviews Design Approval Architecture Exceptions","title":"Cloud Resiliency Guidance"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#cloud-resiliency-guidance","text":"Cloud Resiliency Guidance Introduction Guiding Principles Goals & Objectives Document Scope Out of Scope Resiliency Capabilities Overview AWS Global Infrastructure Design Availability Zones AWS Regions AWS Service Fault Domains Component Scaling Overview of Key Services Route 53 Route 53 Control Plane vs. Data Plane Health Checks Service Discovery Application Load Balancing Global Load Balancing Potential Recovery Limitations API Call Throttling Availability of EC2 instance types Service Quotas State Management Service Recovery Testing Resiliency Requirements & Patterns Component Resiliency Resiliency Patterns Globally Resilient Key Requirements for Globally Resilient workloads Example Globally Resilient Single Page App (SPA) Regionally Resilient Key Requirements for Regionally Resilient workloads Example Single Page App (SPA) Example Service to Service Example Regionally Resilient Kubernetes Application Regionally Resilient with Failover Key Requirements for Regionally Resilient (Manual Failover) workloads Single Region with Standby Key Requirements for Single Region with Standby workloads Single Region Key Requirements for Single Region workloads Sound Recovery Practices Best practices for service recovery Recommended corresponding Architecture Practices Design Reviews Design Approval Architecture Exceptions","title":"Cloud Resiliency Guidance"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#introduction","text":"Cloud resiliency refers to the architecture design practices that contribute to applications, running in AWS, that are resilient to service disrupting events. Service disrupting events can include: * Regional outages * Service instability * Platform instability * Control plane instability * Connectivity issues","title":"Introduction"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#guiding-principles","text":"Southwest Airlines critical business and operations functions depend on applications running in cloud environments hosted by AWS. In order to satisfy Southwest business function requirements and meet availability and recoverability targets, specific guidance and reviews must be in place to support positive resiliency outcomes. Recently, there have been service disruptions, within the AWS platforms and infrastructure, that have negatively impacted technology services that support Southwest Airlines business and operations. Analysis of these events has revealed underlying design flaws that should be addressed in existing designs and new designs.","title":"Guiding Principles"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#goals-objectives","text":"The objectives for this guidance on resiliency are to: 1. Evaluate and understand potential issues and capabilities that contribute or detract from the resiliency of applications running in AWS 2. Provide guidance for resiliency that maps to desired business outcomes 3. Establish architectural patterns that clearly describe how applications can be designed to avoid unnecessary outages 4. Describe best practices for implementing a service recovery and testing program 4. Recommended changes to architecture practices to enhance focus on application resiliency","title":"Goals &amp; Objectives"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#document-scope","text":"","title":"Document Scope"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#out-of-scope","text":"The following topics are considered out of scope for this Architecture Design Document: * While health monitoring may be covered as a topic to manage component failures, general observability and dashboarding of application health is outside the scope of this document. * The resiliency of data platforms, including operational, analytical, and streaming data platforms will be covered in Cloud Data Resiliency Guidance.","title":"Out of Scope"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#resiliency-capabilities-overview","text":"The following capabilities are relevant to resiliency in cloud. A brief description and discussion of relevance is included, but full documentation of these capabilities is beyond the scope of this document.","title":"Resiliency Capabilities Overview"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#aws-global-infrastructure-design","text":"AWS provides globally available infrastructure for use by their customers. That infrastructure is comprised of data centers, Availability Zones (AZ)s, and Regions. The most up to date information on AZs and Regions can always be found on the AWS Website .","title":"AWS Global Infrastructure Design"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#availability-zones","text":"An Availability Zone (AZ) is one or more discrete data centers with redundant power, networking, and connectivity in an AWS Region. For context, an AZ is the equivalent of the SWA SDC or WNDC data center.","title":"Availability Zones"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#aws-regions","text":"AWS has the concept of a Region, which is a physical location around the world where they cluster data centers. Each group of logical data centers are referenced as an Availability Zone. Each AWS Region consists of multiple, isolated, and physically separate AZs within a geographic area.","title":"AWS Regions"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#aws-service-fault-domains","text":"Solution resiliency is a byproduct of individual service resiliency. The first aspect of any solution that should be examined is the resiliency of each component that the solution is comprised of. The table below describes patterns of component resiliency that are used throughout this guidance document. Service Domain Description Examples Global These services are available even if a Region fails Route 53, IAM, CloudFront Region These services are available even if an Availability Zone fails S3, KMS, Lambda Availability Zone These services will fail if an Availability Zone fails. Additional steps should be taken to provide for regional resiliency EC2, EBS, EFS Instance An instance may fail if a platform within an Availability Zone fails. Additional steps should be taken to examine and understand the availability and recovery characteristics of the platform that the instance runs within. EKS, Container","title":"AWS Service Fault Domains"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#component-scaling","text":"Scaling is a key consideration when planning for application and component level resiliency. Scaling considerations need to balance the need to control costs with those of ensuring resiliency in the event of a failure. For services with critical business functions, (Tier 0, Tier 1), scaling events should be avoided during a failover event, as contention for Control Plane functionality and resources can cause scaling events to fail. For these reasons it is important to tailor the scaling of application components to the overall desired availability. The table below maps component level scaling to the component resiliency patterns above. Component Resiliency Scaling Description Global Component - Scaling managed by AWS Active / Active Component - Components scaled to support 100% of the application workload in a single region Active / Passive with Automated Recovery - Active region scaled to support 100% of the application workload - Passive region is also scaled to support 100% of the application workload. This prevents the passive region from failing to service requests adequately during a failover scenario. Active / Passive with Manual Recovery - Active region scaled to support 100% of the application workload - Passive region is also scaled to support 100% of the application workload. This prevents the passive region from failing to service requests adequately during a failover scenario. Active / Standby - Active region scaled to support 100% of the application workload Single Region - Single region scaled to support 100% of the application workload","title":"Component Scaling"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#overview-of-key-services","text":"In addition to the AWS Infrastructure Design, there are key AWS services and capabilities that, when used correctly, can contribute to the resiliency of applications.","title":"Overview of Key Services"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#route-53","text":"Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) service. Amazon Route 53 effectively connects user requests to infrastructure running in AWS and can also be used to route users to infrastructure outside of AWS. Below are features of Route53 that are relevant for resiliency and failover: DNS Health Checks \u2013 Allows you to monitor the health of your resources such as web servers and email servers. You can optionally configure Amazon CloudWatch alarms for your health checks, so that you receive notification when a resource becomes unavailable. DNS Failover - Along with DNS Health checks, you can configure DNS failover so that Route 53 will route your traffic from an unhealthy resource to a healthy resource. You can choose the active-active failover configuration when you want all of your resources to be available the majority of the time or active-passive when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. Traffic Flow - Makes it easy for you to manage traffic globally through a variety of routing policies, including Latency Based Routing, Geo DNS, Geoproximity, and Weighted Round Robin\u2014all of which can be combined with DNS Failover in order to enable a variety of low-latency, fault-tolerant architectures. For more information on routing policies see AWS Routing Policies Using Amazon Route 53 Traffic Flow\u2019s simple visual editor, you can easily manage how your end-users are routed to your application\u2019s endpoints\u2014whether in a single AWS region or distributed around the globe. Application Recover Controller - Gives you insights into whether your applications and resources are ready for recovery, and helps you manage and coordinate failover using readiness check and routing control features","title":"Route 53"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#route-53-control-plane-vs-data-plane","text":"Understanding the different service capabilities of Route 53 and how those capabilities leverage the control plane vs the data plane can be crucial to understanding overall resiliency of Route 53 and how the it will respond in failure and recovery situations. For example, you can rely on the Amazon Route 53 data plane to reliably route DNS queries based on health checks. Updating Route 53 routing policies, DNS weights, and records, however, uses the control plane, and cannot be relied upon for recovery. When implementing recovery or mitigation responses to potentially resiliency-impacting events, using control plane operations can lower the overall resiliency of your architecture. Control Plane The control plane is used to configure services. For Route 53, the control plane has a lower availability design goal than the data plane. The control plane should not be relied upon for service recovery and application resiliency for highly available services in tiers 1 and 2. Data Plane The data plane is used to deliver services. The data plane maintains a much higher uptime commitment. The data plane should be the method by which services instrument high availability. Route 53 health checks are an example of a data plane capability that can aid in application services maintaining high availability.","title":"Route 53 Control Plane vs. Data Plane"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#health-checks","text":"Health checks are a way of asking a service whether or not it is capable of performing work successfully. Examples of health checks include, but are not limited to: Health checks integrated into Route 53 DNS services, which validate underlying service health Load balancers polling services periodically to determine which servers it is safe to direct traffic to. A service that checks its own health before pulling messages off a queue. Monitoring agents that determine the health of a service and raise events or remove a service from service discovery in the event of service degradation. Health checks are a critical part of the design of resilient solutions, as they anticipate and isolate failures, thereby preserving service availability. Health checks need to be designed to mitigate component level failures, but must also take into account the design of the entire solution.","title":"Health Checks"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#service-discovery","text":"Service Discovery is the process of dynamically detecting services available on a network. Resiliency of an application can be enhanced through the use of service discovery. Two models of service discovery exist, server-side and client-side service discovery. In a server-side service discovery model, the server updates its availability with a load-balancer, DNS, or similar system to route traffic to available service endpoints. In a client-side service discovery model, the client queries a service registry to determine available service endpoints and connects to the appropriate one. A full discussion of service discovery is beyond the scope of this design document, and will require a separate design.","title":"Service Discovery"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#application-load-balancing","text":"Application Load Balancers allow for the distribution of incoming requests across service endpoints, while allowing for intelligent health checks, and load distribution algorithms. A limitation of AWS Application Load Balancers is that it they are a regional service, and can only control automated failover across services running in more than one Availability Zone.","title":"Application Load Balancing"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#global-load-balancing","text":"Global load balancing refers to the ability to distribute service requests across a global distribution of service endpoints. Global load balancing in AWS is managed by Route 53 and includes a variety of routing policies, including Latency Based Routing, Geo DNS, Geoproximity, and Weighted Round Robin\u2014all of which can be combined with DNS Failover in order to enable a variety of low-latency, fault-tolerant architectures.","title":"Global Load Balancing"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#potential-recovery-limitations","text":"In the event of a component or application recovery, certain conditions can occur that can limit the ability of the system to self-heal or limit manual recovery efforts. It is important to understand these limitations and design the application and component recovery accordingly.","title":"Potential Recovery Limitations"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#api-call-throttling","text":"Especially in regional recovery scenarios, API throttling or contention, can limit the ability for even automated recovery functions to successfully recover services to a functioning state. This can be further exacerbated when attempting to use the Control Plane for recovery, where overall availability may not match SWA recovery requirements.","title":"API Call Throttling"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#availability-of-ec2-instance-types","text":"In rare circumstances, although increased potential exists during a regional outage, contention for specific EC2 instance types can result in the inability to rapidly provision new instances. Like API calls, this can be exacerbated by Control Plane issues that slow down or prevent instance provisioning events. For this reason, scaling and instance provisioning should be tailored to the availability expectations of the application. Please refer to the Component Scaling section of this guidance.","title":"Availability of EC2 instance types"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#service-quotas","text":"Service quotas can impact application availability and should be managed using a process that balances cost implications of escalating services quotas yet mitigates potential impacts of restricting application scaling or performance. In particular, service quotas can be particularly impactful in failover events where there is increased potential for exceeding currently defined service limits or service quotas. AWS Service Quotas best practices for reliability, from the AWS Well-Architected Framework can be found here, and include: * Aware of service quotas and constraints: You are aware of your default quotas and quota increase requests for your workload architecture. You additionally know which resource constraints, such as disk or network, are potentially impactful. * Manage service quotas across accounts and regions: If you are using multiple AWS accounts or AWS Regions, ensure that you request the appropriate quotas in all environments in which your production workloads run. * Accommodate fixed service quotas and constraints through architecture: Be aware of unchangeable service quotas and physical resources, and architect to prevent these from impacting reliability. * Monitor and manage quotas: Evaluate your potential usage and increase your quotas appropriately allowing for planned growth in usage. * Automate quota management: Implement tools to alert you when thresholds are being approached. By using AWS Service Quotas APIs, you can automate quota increase requests. * Ensure that a sufficient gap exists between the current quotas and the maximum usage to accommodate failover: When a resource fails, it may still be counted against quotas until it is successfully terminated. Ensure that your quotas cover the overlap of all failed resources with replacements before the failed resources are terminated. You should consider an Availability Zone failure when calculating this gap.","title":"Service Quotas"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#state-management","text":"A thorough understanding of the application's dependence on state is necessary to thoroughly understand the ability to successfully recover the application and meet the Recovery Point Objectives of the application. Recovery from failures, including the restoration of state is something that must be tested.","title":"State Management"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#service-recovery-testing","text":"The process of full service recovery must be documented and tested regularly. Additionally, depending on business criticality, Teams should have the appropriate level of automated recovery in place. The table under Resiliency Requirements below describes service recovery and testing requirements. These tests should be run as part of the certification and deployment process, but also run under load, where real-world transactions will stress and expose unexpected situations.","title":"Service Recovery Testing"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#resiliency-requirements-patterns","text":"","title":"Resiliency Requirements &amp; Patterns"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#component-resiliency","text":"Components running only in a single Availability Zone can often times be designed to have a regional or even global resiliency through different configuration patterns. The table below describes patterns of component resiliency that are used throughout this guidance document. Option Description Global Component - Regional resiliency managed by AWS. - Expected to be globally available, and should be used preferentially. - Care must be taken to understand what aspects of a global component, like Route 53, is actually globally available. Active / Active Component - Component service requests are sent to all regions and can be processed independent of other regions. - Care must be taken to configure these services correctly and to understand any required state management. (Either does not depend on state, can use an eventual consistency model, or uses a synchronous replication of state.) -Care must also be taken to understand event sequencing requirements, which can cause transactional or data integrity issues within the larger solution context. Active / Passive Component with Automated Recovery - Component service requests are sent to only one region at a time - Deep health checks are configured to assess regional component health, and recovery automated in the AWS data plane - Component recovery and failback from component recovery must be thoroughly tested to eliminate any issues with data integrity Active / Passive Component with Manual Recovery - Component service requests are sent to only one region - Health checks are configured to assess regional component health - Recovery mechanisms are in place that can be executed without use of the AWS control plane Active / Standby Component - Component service requests are sent to only one region - Health checks are in place to assess regional component health - Processes are in place and have been tested to active standby region components Single Region - Component service requests are sent to only one region - Regional outages will result in loss of service until the region is recovered","title":"Component Resiliency"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#resiliency-patterns","text":"The following resiliency patterns describe the high level characteristics as well as supported Application recovery Hierarchy tiers. Further details can be found within the following documentation of each resiliency pattern, including examples. Resiliency Pattern Characteristics Supported ARH Tiers Globally Resilient - Application components run globally and are resilient to issues impacting more than one region - Service recovery is automatic and self-healing Tier 0, Tier 1 (provided ltency requirements of the application can be met.) Regionally Resilient - Application components run active / active across 2 regions and are resilient to issues impacting a single region - Data is synchronous across regions - Health checks proactively monitor for failed components and isolate failures - Service recovery is automatic and self-healing Tier 0, Tier 1 Regionally Resilient with Failover - Application components run active / passive across 2 regions - Data replication may be asynchronous - Health checks identify failed components, but recovery may be manual in some or all cases Tier 2 Single Region with Standby - Application components run active / standby across 2 regions - Data replication may be asynchronous - Health checks identify failures - Service recovery requires starting the application in a standby region Tier 3+ Single Region - Application components run in a single region - Failures are detected by health checks - Services are recovered once the region has been restored to full operations Tier 4","title":"Resiliency Patterns"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#globally-resilient","text":"Globally resilient architectures extend the Regionally Resilient pattern to include global dispersion of workloads. This means that globally resilient applications are deployed and active in at least 3 regions, across 2 continents, and can withstand failures in more than one region. Component resiliency pattern Preference Global component Allowed Active / Active component Allowed, with design review Active / Passive with automated health check and recovery Not Allowed Active / Passive with manual recovery Not Allowed Active / Standby Not Allowed Single Region Not Allowed","title":"Globally Resilient"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#key-requirements-for-globally-resilient-workloads","text":"The following table shows key requirements for Globally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 3 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Require serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and must leverage automated failover to redirect traffic away from the failed component. | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform |","title":"Key Requirements for Globally Resilient workloads"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#example-globally-resilient-single-page-app-spa","text":"Integrations between components is a critical aspect of achieving true regional resilience.The diagram above depicts a basic pattern for Single Page Apps, with static content being served from S3, and dynamic content being served from one or more lambdas. CloudFront and Route 53 manage traffic routing avoiding any simgle point of failure. Traffic routing at each step is dynamic and can be routed to least latent and available services. * The pattern above leverages CloudFront, Route 53 , S3 replication and API Gateway to create a highly resilient solution. * All services being used have health checks in place to dynamically route traffic to all regions. * Services like lambda and S3 are managed by AWS and do require explicit scaling configurations.","title":"Example Globally Resilient Single Page App (SPA)"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#regionally-resilient","text":"Regionally resilient architectures attempt to eliminate any single failure points within an application across at least 2 regions. Designs need to examine each component to ensure that regional resilience is accounted for. The following component resiliency patterns can be leveraged to design for regionally resilient solutions. Component resiliency pattern Preference Global component Preferred Active / Active component Preferred Active / Passive with automated health check and recovery Allowed Active / Passive with manual recovery Not Allowed Active / Standby Not Allowed Single Region Not Allowed","title":"Regionally Resilient"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#key-requirements-for-regionally-resilient-workloads","text":"The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and automatically redirect traffic away from the failed component . | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform |","title":"Key Requirements for Regionally Resilient workloads"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#example-single-page-app-spa","text":"Integrations between components is a critical aspect of achieving true regional resilience.The diagram above depicts a basic pattern for Single Page Apps, with static content being served from S3, and dynamic content being served from one or more lambdas. Key guidance for Regionally Resilient Single Page Apps: * CloudFront and Route 53 manage traffic routing avoiding any simgle point of failure. Traffic routing at each step is dynamic and can be routed to least latent and available services. * The pattern above leverages CloudFront, Route 53 , S3 replication and API Gateway to create a highly resilient solution. * All services being used have health checks in place to dynamically route traffic to both regions. * Services like lambda and S3 are managed by AWS and do require explicit scaling configurations.","title":"Example Single Page App (SPA)"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#example-service-to-service","text":"Key guidance for Regionally Resilient Service APIs: * CloudFront and Route 53 manage traffic routing avoiding any simgle point of failure. Traffic routing at each step is dynamic and can be routed to least latent and available services. * The pattern above leverages CloudFront, Route 53 , and API Gateway to create a highly resilient solution. * All services being used have health checks in place to dynamically route traffic to both regions. * Services like lambda are managed by AWS and do require explicit scaling configurations.","title":"Example Service to Service"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#example-regionally-resilient-kubernetes-application","text":"Key points for Regionally Resilient EKS container based applications: * EKS clusters exist within a single region and cannot span regions. Each region will have a separate EKS cluster. * EKS cluster nodes should be distributed evenly across at least 3 AZs * Application services, running as containers within EKS, should be evenly distributed across EKS cluster nodes and at least 3 AZs * Route 53 health checks determine health of each region and distribute traffic accordingly * Health monitoring within EKS isolates and restarts unhealth nodes and container workloads, maintaining a minimum of 3 healthy AZs at all times * For Regionally Resilient workloads, capacity of each regional EKS cluster should be scaled to support 100% of the application workload at all times. Scaling of workloads should not be part of the recovery design for the Regionally Resilient pattern, as resource contention and control plane issues can hinder scaling events during regional recovery activities.","title":"Example Regionally Resilient Kubernetes Application"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#regionally-resilient-with-failover","text":"Description Component resiliency pattern Preference Global component Preferred Active / Active component Preferred Active / Passive with automated health check and recovery Preferred Active / Passive with manual recovery Allowed Active / Standby Not Allowed Single Region Not Allowed","title":"Regionally Resilient with Failover"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#key-requirements-for-regionally-resilient-manual-failover-workloads","text":"The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and may leverage automated failover to redirect traffic away from the failed component. | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform |","title":"Key Requirements for Regionally Resilient (Manual Failover) workloads"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#single-region-with-standby","text":"Description Component resiliency pattern Preference Global component Preferred Active / Active component Allowed Active / Passive with automated health check and recovery Allowed Active / Passive with manual recovery Preferred Active / Standby Allowed Single Region Not Allowed","title":"Single Region with Standby"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#key-requirements-for-single-region-with-standby-workloads","text":"The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and automatically redirect traffic away from the failed component . | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform |","title":"Key Requirements for Single Region with Standby workloads"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#single-region","text":"Description Component resiliency pattern Preference Global component Allowed Active / Active component Not Allowed Active / Passive with automated health check and recovery Not Allowed Active / Passive with manual recovery Not Allowed Active / Standby Not Allowed Single Region Preferred","title":"Single Region"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#key-requirements-for-single-region-workloads","text":"The following table shows key requirements for Regionally Resilient workloads. | Criteria | Requirement | | :------- | :------- | | Regional Availability | All services are running in at least 2 regions | | Availablility Zones | Where applicable, all services are running in at least 3 AZs per region | | Compute | Prefer serverless compute, due to stateless nature and auto-scaling | | Scaling | Application scaled to support 100% of the workload in a single region | | Health Checks | Health Checks have been implemented to detect failures and automatically redirect traffic away from the failed component . | | Failover Control | Failover must leverage the data plane of the AWS service. Failover cannot require the use of AWS Console or CICD Tools. | | Monitoring | All components have health monitoring instrumented in an approved oberservability platform |","title":"Key Requirements for Single Region workloads"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#sound-recovery-practices","text":"","title":"Sound Recovery Practices"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#best-practices-for-service-recovery","text":"Service preference: When designing applications, prefer AWS Global and AWS Regional services to minimize recovery effort and control scaling costs. Prefer serverless: This applies to compute workloads as well. Service design should prefer serverless designs over alternatives, as serverless designs require externalizing state, eliminate scaling issues, and Start with components: Start by understanding how each component will behave in a failure scenario, and understand and document recovery processes. Understand data resiliency: Data resiliency is a key part of understanding the ability to effectively recover any service. Key data dependencies, like the data consistency model, must be thoroughly understood. Data replication, backup, and recovery processes play a critical role in overall system recovery. Separate Data Resiliency guidance will address the specific aspects of data resiliency. Prefer automation: Service recovery automaton is a key non-functional requirement for services and should be part of the architecture design process. a. For known use cases, automate intelligent and deep health checks that uncover service issues and isolate failures. b. To raise overall service availability, extend automation to self-healing activities that remove human interaction. Required for some resiliency patterns . Test often: Test failure scenarios frequently. Build automated integration tests that validate heath checks and recovery solutions. Perform thought experiments to uncover new scenarios that may lead to failures. Assume the worst: Assume everything will fail eventually and be sure that those failure scenarios have been tested and behave as expected.","title":"Best practices for service recovery"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#recommended-corresponding-architecture-practices","text":"","title":"Recommended corresponding Architecture Practices"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#design-reviews","text":"","title":"Design Reviews"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#design-approval","text":"","title":"Design Approval"},{"location":"Technical_Architecture/Cloud%20Resiliency/Cloud_Resiliency_Guidance/#architecture-exceptions","text":"","title":"Architecture Exceptions"}]}